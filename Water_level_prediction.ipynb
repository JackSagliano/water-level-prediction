{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JackSagliano/water-level-prediction/blob/main/Water_level_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LOYxO-vJ1Okq",
      "metadata": {
        "id": "LOYxO-vJ1Okq"
      },
      "source": [
        "Vento U e Vento V (Vettori del vento)\n",
        "- Vento U (Zonale): Rappresenta il movimento lungo l'asse Est-Ovest.\n",
        "  - Valore positivo: il vento soffia verso Est.\n",
        "  - Valore negativo: il vento soffia verso Ovest.\n",
        "- Vento V (Meridionale): Rappresenta il movimento lungo l'asse Nord-Sud.\n",
        "  - Valore positivo: il vento soffia verso Nord.\n",
        "  - Valore negativo: il vento soffia verso Sud.\n",
        "\n",
        "Il vento che crea più problemi a Venezia è lo Scirocco, che soffia da Sud-Est verso Nord-Ovest. Nel tuo dataset, lo Scirocco apparirà come una combinazione di V negativo (molto forte) e U negativo.\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "\n",
        "Le Effemeridi (Marea Astronomica)\n",
        "  - Le effemeridi descrivono la posizione relativa della Terra, della Luna e del Sole. Sono dati puramente astronomici e prevedibili al 100% per i prossimi secoli. Le effemeridi, in questo notebook, sono descritte da 6 variabili normalizzate e descrivono i cicli che causano la marea deterministica:\n",
        "    - Ciclo Semidiurno e Diurno: L'innalzamento e abbassamento regolare dovuto all'attrazione gravitazionale della Luna e del Sole.\n",
        "    - Ciclo Mensile: Le fasi lunari (luna piena/nuova portano maree più alte).\n",
        "\n",
        "  Perché servono alla rete? Il livello dell'acqua che devi prevedere è la somma di:\n",
        "  $$\\text{Livello Totale} = \\text{Marea Astronomica (Effemeridi)} + \\text{Storm Surge (Vento + Pressione)}$$\n",
        "\n",
        "  Senza le effemeridi, la tua rete non saprebbe mai se l'acqua è alta perché c'è tempesta o semplicemente perché è il momento dell'alta marea lunare."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_WktTZI43h5S",
      "metadata": {
        "id": "_WktTZI43h5S"
      },
      "source": [
        "# Water level prediction using ERA5\n",
        "\n",
        "## Problem description\n",
        "Given a set of  5,000  nodes over the Northern Adriatic Sea, defined by varying longitude and latitude (visualized as red spots in image below), you are supposed to infer the water level of these points at each hour in a given range, using a neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X47iHHpo41Zx",
      "metadata": {
        "id": "X47iHHpo41Zx"
      },
      "outputs": [],
      "source": [
        "#import base64\n",
        "#from IPython.display import HTML, display\n",
        "\n",
        "#with open(\"graphical_visualization.png\", \"rb\") as f:\n",
        "#    encoded = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "#\n",
        "#display(HTML(f\"\"\"<img src=\"data:image/png;base64,{encoded}\" width=\"800\"/>\"\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ef925d3",
      "metadata": {
        "id": "4ef925d3"
      },
      "source": [
        "The information you can use to predict these values are:\n",
        "* **latitude** and **longitude** of the nodes\n",
        "* the **ephemerides** relative to the sun and the moon at each hour (we consider a single value of the ephemeridies for the whole region). Ephemerides are key predictors of tidal motion and are therefore important for the prediction of water level. The provided values of the ephemerides are already normalized.\n",
        "* **weather variables** (wind components and pressure) derived from ERA5 dataset (not normalized). Due to the low resolution of ERA5, these values are organized as an array of shape $5 \\times 9$ for each hour and each variable. A supporting function is provided to convert a given (latitude, longitude) of a node to the associated index of ERA5 array. Weather variables are important to predict phenomenon such as storm surge: another key component of water level.\n",
        "\n",
        "For the prediction of the water level at timestamp $t$, you are allowed to use a sequence of any length of the input variables relative to past timesteps, but no future information. The output variable (corresponding to the **water level**) **CANNOT** be used as input to the model, not even for past timestamps.   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tcvPfF2N5_ip",
      "metadata": {
        "id": "tcvPfF2N5_ip"
      },
      "source": [
        "# Data Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "PSTF_E-B6Gdv",
      "metadata": {
        "id": "PSTF_E-B6Gdv"
      },
      "outputs": [],
      "source": [
        "import gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nUpnb_m4CkH4",
      "metadata": {
        "id": "nUpnb_m4CkH4"
      },
      "source": [
        "train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "M1XC_yba_97q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1XC_yba_97q",
        "outputId": "efbf9204-0766-4332-f679-f738a544a154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve file url:\n",
            "\n",
            "\tToo many users have viewed or downloaded this file recently. Please\n",
            "\ttry accessing the file again later. If the file you are trying to\n",
            "\taccess is particularly large or is shared with many people, it may\n",
            "\ttake up to 24 hours to be able to view or download the file. If you\n",
            "\tstill can't access a file after 24 hours, contact your domain\n",
            "\tadministrator.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1Ncexf_vB55cpiCeNr-hIRrdpquYaav6B\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        }
      ],
      "source": [
        "!gdown 1Ncexf_vB55cpiCeNr-hIRrdpquYaav6B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "--k6kIuhBhwH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--k6kIuhBhwH",
        "outputId": "6edce547-f342-422d-cb9b-410f7c650406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve file url:\n",
            "\n",
            "\tToo many users have viewed or downloaded this file recently. Please\n",
            "\ttry accessing the file again later. If the file you are trying to\n",
            "\taccess is particularly large or is shared with many people, it may\n",
            "\ttake up to 24 hours to be able to view or download the file. If you\n",
            "\tstill can't access a file after 24 hours, contact your domain\n",
            "\tadministrator.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1THbGvO9mVjg_wfZTabRbQBOVpaECl3my\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        }
      ],
      "source": [
        "!gdown 1THbGvO9mVjg_wfZTabRbQBOVpaECl3my"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ublUtPdmCHgv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ublUtPdmCHgv",
        "outputId": "444e7359-485f-4613-acdc-34bb13c24593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve file url:\n",
            "\n",
            "\tToo many users have viewed or downloaded this file recently. Please\n",
            "\ttry accessing the file again later. If the file you are trying to\n",
            "\taccess is particularly large or is shared with many people, it may\n",
            "\ttake up to 24 hours to be able to view or download the file. If you\n",
            "\tstill can't access a file after 24 hours, contact your domain\n",
            "\tadministrator.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=16M1zB54PKkKS6SK8W_U83UURWu1T_AxR\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        }
      ],
      "source": [
        "!gdown 16M1zB54PKkKS6SK8W_U83UURWu1T_AxR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ecuafLFFBHm6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecuafLFFBHm6",
        "outputId": "ad5718ad-4b88-4cf6-a8f8-0e5a0a38c8b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve file url:\n",
            "\n",
            "\tToo many users have viewed or downloaded this file recently. Please\n",
            "\ttry accessing the file again later. If the file you are trying to\n",
            "\taccess is particularly large or is shared with many people, it may\n",
            "\ttake up to 24 hours to be able to view or download the file. If you\n",
            "\tstill can't access a file after 24 hours, contact your domain\n",
            "\tadministrator.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=161OYs8KQSn3RrXezCNwFvOewXLJe5wBf\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        }
      ],
      "source": [
        "!gdown 161OYs8KQSn3RrXezCNwFvOewXLJe5wBf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oZ6fBOfBCoK5",
      "metadata": {
        "id": "oZ6fBOfBCoK5"
      },
      "source": [
        "test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "epPokkxMCg-e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epPokkxMCg-e",
        "outputId": "bf8260f5-4c27-48af-d2dd-1f7f684f6691"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve file url:\n",
            "\n",
            "\tToo many users have viewed or downloaded this file recently. Please\n",
            "\ttry accessing the file again later. If the file you are trying to\n",
            "\taccess is particularly large or is shared with many people, it may\n",
            "\ttake up to 24 hours to be able to view or download the file. If you\n",
            "\tstill can't access a file after 24 hours, contact your domain\n",
            "\tadministrator.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1iwqd4xzHc98OYqBpGsuUW4SG5AQDtdNR\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        }
      ],
      "source": [
        "!gdown 1iwqd4xzHc98OYqBpGsuUW4SG5AQDtdNR #(8784, 5000)  hours,nodes water levels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8Kv_rCEoDEh1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Kv_rCEoDEh1",
        "outputId": "d2cdd2d6-98cf-422a-ccb3-88233d0af3b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve file url:\n",
            "\n",
            "\tToo many users have viewed or downloaded this file recently. Please\n",
            "\ttry accessing the file again later. If the file you are trying to\n",
            "\taccess is particularly large or is shared with many people, it may\n",
            "\ttake up to 24 hours to be able to view or download the file. If you\n",
            "\tstill can't access a file after 24 hours, contact your domain\n",
            "\tadministrator.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1cHqyeXtmaiC_3v9uadMD7Y0hONGf2R1q\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        }
      ],
      "source": [
        "!gdown 1cHqyeXtmaiC_3v9uadMD7Y0hONGf2R1q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "M53jF-n3Dh2m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M53jF-n3Dh2m",
        "outputId": "b9e1d400-44b9-41f2-b743-9575f450632e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve file url:\n",
            "\n",
            "\tToo many users have viewed or downloaded this file recently. Please\n",
            "\ttry accessing the file again later. If the file you are trying to\n",
            "\taccess is particularly large or is shared with many people, it may\n",
            "\ttake up to 24 hours to be able to view or download the file. If you\n",
            "\tstill can't access a file after 24 hours, contact your domain\n",
            "\tadministrator.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1AoFAD2viMarikhU5b5Etdsklx08EzKKb\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        }
      ],
      "source": [
        "!gdown 1AoFAD2viMarikhU5b5Etdsklx08EzKKb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "zGAcWZ1dBpGA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGAcWZ1dBpGA",
        "outputId": "2aedbf60-c977-4431-9537-b08ad8499a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve file url:\n",
            "\n",
            "\tToo many users have viewed or downloaded this file recently. Please\n",
            "\ttry accessing the file again later. If the file you are trying to\n",
            "\taccess is particularly large or is shared with many people, it may\n",
            "\ttake up to 24 hours to be able to view or download the file. If you\n",
            "\tstill can't access a file after 24 hours, contact your domain\n",
            "\tadministrator.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1sWoTlJih-mqDdP9TBzhyXTqHHS5Jr9fe\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        }
      ],
      "source": [
        "!gdown 1sWoTlJih-mqDdP9TBzhyXTqHHS5Jr9fe"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wHz08HN5EWrf",
      "metadata": {
        "id": "wHz08HN5EWrf"
      },
      "source": [
        "latitude and longitude of nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "akAyZ4T-Ei6g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akAyZ4T-Ei6g",
        "outputId": "0ea3a91b-a4a9-4b6e-c4ef-092219b90304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Mg52QAIo4bfpzJF0dsI8mpZf09tHTzj8\n",
            "To: /content/lon.npy\n",
            "100% 20.1k/20.1k [00:00<00:00, 59.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wWz0EWbGiBkZ0vfJD8KeZkmVZfmRiYLk\n",
            "To: /content/lat.npy\n",
            "100% 20.1k/20.1k [00:00<00:00, 57.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1Mg52QAIo4bfpzJF0dsI8mpZf09tHTzj8\n",
        "!gdown 1wWz0EWbGiBkZ0vfJD8KeZkmVZfmRiYLk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d2c5535",
      "metadata": {
        "id": "1d2c5535"
      },
      "source": [
        "## File description\n",
        "\n",
        "Spatial coordinates\n",
        "\n",
        "`lat.npy`\n",
        "- latitudes of the 5000 target nodes,\n",
        "- shape (5000,)\n",
        "\n",
        "`lon.npy` :\n",
        "- longitudes of the 5000 target nodes\n",
        "- shape (5000,)\n",
        "\n",
        "## Training data\n",
        "\n",
        "hourly values from 01/01/2010 until 31/12/2019 (87648 hours)\n",
        "\n",
        "`wl_2010-2019.npy`\n",
        "- Water level measurements.\n",
        "- Shape: (87648, 5000)\n",
        "\n",
        "`dist_alt_az_moon-sun_coord13-45_2010-2019_norm.npy`\n",
        "- Ephemerides features\n",
        "- Shape: (6, 87648)\n",
        "\n",
        "`ERA5_adriatic_u10v10sp_2010-2019.npy`\n",
        "- ERA5 predictors (variables, timestamps, x , y)\n",
        "- Shape: (3, 87648, 5, 9)\n",
        "\n",
        "`tvec_2010-2019.npy`\n",
        "- Explicit time information\n",
        "- Shape: (87648)\n",
        "\n",
        "## Test data\n",
        "\n",
        "hourly values from 01/01/2020 until 31/12/2020 (8784 hours)\n",
        "\n",
        "`wl_2020.npy`\n",
        "- Water level measurements, Shape: (8784, 5000)\n",
        "\n",
        "`dist_alt_az_moon-sun_coord13-45_2020_norm.npy`\n",
        "- Ephemerides features\n",
        "- Shape: (6, 8784)\n",
        "\n",
        "`ERA5_adriatic_u10v10sp_2020.npy`\n",
        "- ERA5 predictors (variables, timestamps, x , y)\n",
        "- Shape: (3, 8784, 5, 9)\n",
        "\n",
        "`tvec_2020.npy`\n",
        "- Explicit time information\n",
        "- Shape: (87648)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XIS2EjueH2Np",
      "metadata": {
        "id": "XIS2EjueH2Np"
      },
      "source": [
        "## We use cartopy for visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "V_qSVFkQGEho",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_qSVFkQGEho",
        "outputId": "d18bb86b-4c56-4c06-e416-2ca2396122d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cartopy in /usr/local/lib/python3.12/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from cartopy) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.12/dist-packages (from cartopy) (3.10.0)\n",
            "Requirement already satisfied: shapely>=2.0 in /usr/local/lib/python3.12/dist-packages (from cartopy) (2.1.2)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from cartopy) (25.0)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.12/dist-packages (from cartopy) (3.0.3)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.12/dist-packages (from cartopy) (3.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->cartopy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->cartopy) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->cartopy) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->cartopy) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->cartopy) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->cartopy) (2.9.0.post0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from pyproj>=3.3.1->cartopy) (2026.1.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->cartopy) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install cartopy\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import cartopy.io.img_tiles as cimgt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "556708a7",
      "metadata": {
        "id": "556708a7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ceb6836e",
      "metadata": {
        "id": "ceb6836e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "dd6e8aea-077a-46b5-e634-aa190821a0d9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 99876832 into shape (5000,87648)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2658653153.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#load train data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_wl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./wl_2010-2020.npy\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (87648, 5000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtrain_ephem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./dist_alt_az_moon-sun_coord13-45_2010-2019_norm.npy\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (6, 87648)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrain_era5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./ERA5_adriatic_u10v10sp_2010-2019.npy\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (3, 87648, 5, 9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    482\u001b[0m                                           max_header_size=max_header_size)\n\u001b[1;32m    483\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0m\u001b[1;32m    485\u001b[0m                                          \u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                                          max_header_size=max_header_size)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfortran_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 99876832 into shape (5000,87648)"
          ]
        }
      ],
      "source": [
        "# load nodes coordinates\n",
        "lat_vec = np.load(\"./lat.npy\") # (5000, )\n",
        "lon_vec = np.load(\"./lon.npy\") # (5000, )\n",
        "\n",
        "#load train data\n",
        "train_wl = np.load(\"./wl_2010-2020.npy\") # (87648, 5000)\n",
        "train_ephem = np.load(\"./dist_alt_az_moon-sun_coord13-45_2010-2019_norm.npy\") # (6, 87648)\n",
        "train_era5 = np.load(\"./ERA5_adriatic_u10v10sp_2010-2019.npy\") # (3, 87648, 5, 9)\n",
        "train_tvec = np.load(\"./tvec_2010-2019.npy\") # (6, 87648))\n",
        "\n",
        "#load test data\n",
        "test_wl = np.load(\"./wl_2020.npy\") # (8784, 5000)\n",
        "test_ephem = np.load(\"./dist_alt_az_moon-sun_coord13-45_2020_norm.npy\") # (6, 8784)\n",
        "test_era5 = np.load(\"./ERA5_adriatic_u10v10sp_2020.npy\")#(3, 8784, 5, 9)\n",
        "test_tvec = np.load(\"./tvec_2020.npy\") # (6,8784)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5234eb03",
      "metadata": {
        "id": "5234eb03"
      },
      "source": [
        "## Data description\n",
        "\n",
        "**ERA5:**\n",
        "- Gridded, hourly atmospheric data\n",
        "- Spatial resolution: $5 \\times 9$ grid over the study area\n",
        "- 3 variables: u10, v10 (10m wind components), surface pressure\n",
        "- explicit time: Year,Month,Day,Hour,Minute,Second\n",
        "\n",
        "**EPHEMERIDES:**\n",
        "- 6 scalar features describing Moon–Sun geometry\n",
        "  (e.g. distance, altitude, azimuth)\n",
        "- Hourly resolution\n",
        "- Spatially constant (same values for all target nodes)\n",
        "\n",
        "**TARGET:**\n",
        "- Water level at 5000 spatial nodes in the Northern Adriatic\n",
        "- Each node has fixed latitude and longitude\n",
        "- A function is provided to match node coordinates to the closest era5 data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "106eca16",
      "metadata": {
        "id": "106eca16"
      },
      "outputs": [],
      "source": [
        "# utilities functions\n",
        "def get_era5_coord(lat, lon):\n",
        "    \"\"\"\n",
        "    Function to get era5 data from data coordinates\n",
        "    \"\"\"\n",
        "    era5_row, era5_col = 5, 9\n",
        "    lat_min, lat_max = 44.94972, 45.8\n",
        "    lon_min, lon_max = 12.12863, 13.81283\n",
        "\n",
        "    delta_lat = lat_max - lat_min\n",
        "    delta_lon = lon_max - lon_min\n",
        "\n",
        "    lon_coord = np.ceil((lon - lon_min) / delta_lon * (era5_col -1))\n",
        "    lat_coord = 4 - np.ceil((lat - lat_min) / delta_lat * (era5_row - 1))\n",
        "\n",
        "    return int(lat_coord), int(lon_coord)\n",
        "\n",
        "def RMSE(wl_true, wl_pred):\n",
        "    \"\"\"\n",
        "    Root mean squared error\n",
        "    \"\"\"\n",
        "    return np.sqrt(np.mean(np.square(wl_pred - wl_true)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "vMyCJxvuJiHS",
      "metadata": {
        "id": "vMyCJxvuJiHS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "d1791f75-eced-4628-a73a-867dcecc1208"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_wl' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3317201833.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#example of usage of get_era5_coord\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnode_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_wl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mera5_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_era5_coord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_number\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlon_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_number\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ERA5 grid coords for node {node_number}: {era5_coords}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhour\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_wl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_wl' is not defined"
          ]
        }
      ],
      "source": [
        "#example of usage of get_era5_coord\n",
        "node_number = np.random.randint(np.shape(test_wl)[1])\n",
        "era5_coords = get_era5_coord(lat_vec[node_number], lon_vec[node_number])\n",
        "print(f\"ERA5 grid coords for node {node_number}: {era5_coords}\")\n",
        "hour = np.random.randint(np.shape(test_wl)[1])\n",
        "print(test_tvec[:,hour])\n",
        "hour_time = datetime(*test_tvec[:,hour].astype(int))\n",
        "print(hour_time)\n",
        "wind0,wind1,pression = test_era5[:,hour,era5_coords[0],era5_coords[1]]\n",
        "print(f\"node {node_number} at time {hour_time} (no {hour}): wind0 = {wind0:.3f}, wind1 = {wind1:1.3f}, pression ={pression:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w8dwsgtMMuwN",
      "metadata": {
        "id": "w8dwsgtMMuwN"
      },
      "source": [
        "As you may observe, wind and especially pressure **are not normalized!!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0cc032d",
      "metadata": {
        "id": "b0cc032d"
      },
      "outputs": [],
      "source": [
        "# Visualize a single node variability,\n",
        "plt.plot(test_wl[:200, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o7rmj5VYNOC_",
      "metadata": {
        "id": "o7rmj5VYNOC_"
      },
      "source": [
        "In the picture above you may easily recognize the tydal cycle, with a period of approximately 24 hours."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1360357b",
      "metadata": {
        "id": "1360357b"
      },
      "outputs": [],
      "source": [
        "# Create figure and map\n",
        "fig, ax = plt.subplots(figsize=(16, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
        "(lat_min, lat_max), (lon_min, lon_max) = (lat_vec.min(), lat_vec.max()), (lon_vec.min(), lon_vec.max())\n",
        "ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n",
        "\n",
        "stamen_terrain = cimgt.GoogleTiles(style='satellite')\n",
        "ax.add_image(stamen_terrain, 10)\n",
        "\n",
        "ax.add_feature(cfeature.RIVERS, edgecolor='cyan', linewidth=0.5)\n",
        "ax.add_feature(cfeature.BORDERS, linestyle='-', edgecolor='white', alpha=0.5)\n",
        "ax.add_feature(cfeature.STATES, linestyle=':', edgecolor='white', alpha=0.5)\n",
        "\n",
        "# Gridlines\n",
        "gl = ax.gridlines(draw_labels=True, linewidth=1, color='gray', alpha=0.3, linestyle='--')\n",
        "gl.top_labels = gl.right_labels = False\n",
        "\n",
        "# Plot red dots\n",
        "# Note: Ensure data is visible against the varied satellite background\n",
        "sc = ax.scatter(lon_vec, lat_vec, cmap=\"viridis\", c=\"r\", s=5, marker='o', transform=ccrs.PlateCarree(), vmin=0.07, vmax=0.15)\n",
        "# Increased 's' (size) slightly to make dots visible against satellite texture\n",
        "\n",
        "plt.title(f'Node map')\n",
        "plt.savefig(\"graphical_visualization.png\", dpi=400)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gZWzUlSIIEpR",
      "metadata": {
        "id": "gZWzUlSIIEpR"
      },
      "source": [
        "# What to deliver\n",
        "\n",
        "The problem consists in inferring the water level for all nodes in the test set (year 2020).\n",
        "\n",
        "The solution must be evaluated using RMSE with respect to the given test values.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Cu7WGjHWN8Ci",
      "metadata": {
        "id": "Cu7WGjHWN8Ci"
      },
      "source": [
        "As an indicative baseline, you may consider persistence, namely using the water level of the previous timestep to predict the current value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lwds7NTGJNxK",
      "metadata": {
        "id": "lwds7NTGJNxK"
      },
      "outputs": [],
      "source": [
        "print(f\"persistence baseline: {RMSE(test_wl[:-1],test_wl[1:]):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MO-pAHhCOSqp",
      "metadata": {
        "id": "MO-pAHhCOSqp"
      },
      "source": [
        "Any marginal improvement w.r.t. the baseline is significant.\n",
        "\n",
        "As usual, you are supposed to upload a single notebook with your solution, evidence of training, and the final RMSE.\n",
        "\n",
        "Please note that the model **cannot use** sea levels of previous times steps."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "NZg8P860sAxJ"
      },
      "id": "NZg8P860sAxJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Caricamento file (nomi standard del progetto)\n",
        "ephem_train = np.load('dist_alt_az_moon-sun_coord13-45_2010-2019_norm.npy')\n",
        "era5_train = np.load('era5_2010-2019_12-14_44-46.npy') # (ore, 5, 9, 3)\n",
        "targets_train = np.load('targets_2010-2019.npy') # (ore, 5000)\n",
        "coords = np.load('coords.npy') # (5000, 2)\n",
        "\n",
        "# Funzione di mappatura fornita dal prof\n",
        "def get_era5_coord(lon, lat):\n",
        "    era_lon = np.arange(12, 14.25, 0.25)\n",
        "    era_lat = np.arange(44, 46.25, 0.25)\n",
        "    return np.argmin(np.abs(era_lon - lon)), np.argmin(np.abs(era_lat - lat))\n",
        "\n",
        "# Mappatura nodi -> indici griglia meteo\n",
        "node_to_era_idx = np.array([get_era5_coord(c[0], c[1]) for c in coords])\n",
        "\n",
        "# Normalizzazione Coordinate\n",
        "lat_mean, lat_std = coords[:, 1].mean(), coords[:, 1].std()\n",
        "lon_mean, lon_std = coords[:, 0].mean(), coords[:, 0].std()\n",
        "coords_norm = np.zeros_like(coords)\n",
        "coords_norm[:, 1] = (coords[:, 1] - lat_mean) / lat_std\n",
        "coords_norm[:, 0] = (coords[:, 0] - lon_mean) / lon_std\n",
        "\n",
        "# Normalizzazione ERA5 (calcolata su train)\n",
        "era_mean = era5_train.mean(axis=(0, 1, 2))\n",
        "era_std = era5_train.std(axis=(0, 1, 2))\n",
        "era5_train_norm = (era5_train - era_mean) / era_std"
      ],
      "metadata": {
        "id": "rLb8xomqsGB5"
      },
      "id": "rLb8xomqsGB5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdriaticDataset(Dataset):\n",
        "    def __init__(self, era_data, ephem_data, targets, coords, node_map, seq_len=24, nodes_per_epoch=5000):\n",
        "        self.era_data = era_data\n",
        "        self.ephem_data = ephem_data\n",
        "        self.targets = targets\n",
        "        self.coords = coords\n",
        "        self.node_map = node_map\n",
        "        self.seq_len = seq_len\n",
        "        self.num_hours = era_data.shape[0]\n",
        "        self.nodes_per_epoch = nodes_per_epoch # Possiamo limitare per accelerare il training\n",
        "\n",
        "        # Creiamo un set di indici (ora, nodo) validi\n",
        "        # Nota: per brevità qui facciamo training su tutti i nodi\n",
        "        self.samples = []\n",
        "        # Esempio: usiamo una sottocampionatura per non avere milioni di righe\n",
        "        # Prendiamo un nodo ogni 10 per l'addestramento veloce\n",
        "        for t in range(seq_len, self.num_hours, 2): # Saltiamo 1 ora su 2\n",
        "            for n in range(0, 5000, 50): # Un nodo ogni 50\n",
        "                self.samples.append((t, n))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        t, n = self.samples[idx]\n",
        "\n",
        "        # Estrazione sequenza meteo corretta per quel nodo\n",
        "        lon_idx, lat_idx = self.node_map[n]\n",
        "        weather_seq = self.era_data[t-self.seq_len:t, lon_idx, lat_idx, :] # (seq_len, 3)\n",
        "\n",
        "        # Effemeridi ora attuale\n",
        "        ephem = self.ephem_data[t] # (6,)\n",
        "\n",
        "        # Coordinate nodo\n",
        "        coord = self.coords[n] # (2,)\n",
        "\n",
        "        target = self.targets[t, n]\n",
        "\n",
        "        return {\n",
        "            'weather': torch.FloatTensor(weather_seq).transpose(0, 1), # (3, 24) per CNN\n",
        "            'ephem': torch.FloatTensor(ephem),\n",
        "            'coord': torch.FloatTensor(coord),\n",
        "            'target': torch.FloatTensor([target])\n",
        "        }\n",
        "\n",
        "# Divisione 2010-2018 (Train) e 2019 (Val)\n",
        "train_end = 8760 * 9\n",
        "train_ds = AdriaticDataset(era5_train_norm[:train_end], ephem_train[:train_end], targets_train[:train_end], coords_norm, node_to_era_idx)\n",
        "val_ds = AdriaticDataset(era5_train_norm[train_end:], ephem_train[train_end:], targets_train[train_end:], coords_norm, node_to_era_idx)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=256)"
      ],
      "metadata": {
        "id": "s06rBEHHsKR6"
      },
      "id": "s06rBEHHsKR6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WaterLevelModel(nn.Module):\n",
        "    def __init__(self, seq_len=24):\n",
        "        super(WaterLevelModel, self).__init__()\n",
        "\n",
        "        # Ramo Meteo (CNN 1D)\n",
        "        self.weather_cnn = nn.Sequential(\n",
        "            nn.Conv1d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "\n",
        "        # Ramo Coordinate\n",
        "        self.coord_enc = nn.Sequential(\n",
        "            nn.Linear(2, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Fusione finale\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(128 + 16 + 6, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, w, e, c):\n",
        "        w_feat = self.weather_cnn(w).squeeze(-1) # (batch, 128)\n",
        "        c_feat = self.coord_enc(c)               # (batch, 16)\n",
        "        combined = torch.cat([w_feat, c_feat, e], dim=1)\n",
        "        return self.regressor(combined)\n",
        "\n",
        "model = WaterLevelModel().to(device)"
      ],
      "metadata": {
        "id": "w8uJp_Y-sKIe"
      },
      "id": "w8uJp_Y-sKIe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 20\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    t_loss = 0\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "        w, e, c, t = batch['weather'].to(device), batch['ephem'].to(device), batch['coord'].to(device), batch['target'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(w, e, c)\n",
        "        loss = criterion(out, t)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        t_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    v_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            w, e, c, t = batch['weather'].to(device), batch['ephem'].to(device), batch['coord'].to(device), batch['target'].to(device)\n",
        "            out = model(w, e, c)\n",
        "            v_loss += criterion(out, t).item()\n",
        "\n",
        "    train_losses.append(t_loss / len(train_loader))\n",
        "    val_losses.append(v_loss / len(val_loader))\n",
        "    print(f\"Train Loss: {train_losses[-1]:.6f} | Val Loss: {val_losses[-1]:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "vIxRhoalsPvS",
        "outputId": "bd39f303-eaab-4f25-bcde-ef164284a668"
      },
      "id": "vIxRhoalsPvS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1277478749.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Caricamento dati 2020\n",
        "era5_2020 = np.load('era5_2020_12-14_44-46.npy')\n",
        "ephem_2020 = np.load('dist_alt_az_moon-sun_coord13-45_2020_norm.npy')\n",
        "era5_2020_norm = (era5_2020 - era_mean) / era_std\n",
        "\n",
        "model.eval()\n",
        "num_hours = era5_2020.shape[0]\n",
        "all_preds = np.zeros((num_hours, 5000))\n",
        "\n",
        "print(\"Generating predictions for 2020...\")\n",
        "with torch.no_grad():\n",
        "    for t in tqdm(range(24, num_hours)):\n",
        "        # Prepariamo input per tutti i 5000 nodi (a blocchi per RAM GPU)\n",
        "        for node_batch in range(0, 5000, 1000):\n",
        "            n_end = node_batch + 1000\n",
        "\n",
        "            # Weather per questo blocco di nodi\n",
        "            batch_w = []\n",
        "            for n in range(node_batch, n_end):\n",
        "                lon_i, lat_i = node_to_era_idx[n]\n",
        "                batch_w.append(era5_2020_norm[t-24:t, lon_i, lat_i, :])\n",
        "\n",
        "            w_tensor = torch.FloatTensor(np.array(batch_w)).transpose(1, 2).to(device)\n",
        "            e_tensor = torch.FloatTensor(ephem_2020[t]).repeat(1000, 1).to(device)\n",
        "            c_tensor = torch.FloatTensor(coords_norm[node_batch:n_end]).to(device)\n",
        "\n",
        "            preds = model(w_tensor, e_tensor, c_tensor)\n",
        "            all_preds[t, node_batch:n_end] = preds.cpu().numpy().flatten()\n",
        "\n",
        "np.save('previsioni_2020.npy', all_preds)\n",
        "print(\"File previsioni_2020.npy salvato con successo!\")"
      ],
      "metadata": {
        "id": "w8Um51pUsRLR"
      },
      "id": "w8Um51pUsRLR",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}